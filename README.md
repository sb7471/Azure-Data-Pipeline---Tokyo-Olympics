To summarize, I created an Azure storage account, built a data factory pipeline to ingest data files from the source to the raw folder of Azure Data Lake Storage gen2, used Azure Data Bricks to perform cleaning and transformation on the data, and uploaded them to Azure Data Lake Storage gen2 transformed folder. Finally, I prepared a dashboard in Power BI and published it in Azure Synapse workspace.


![image](https://github.com/sb7471/Azure-Data-Pipeline---Tokyo-Olympics/assets/72674093/f8122322-4a7a-4255-93e8-52a5077593d5)
